PROJECT NOCTEM RESEARCH SYNTHESIS
Academic Literature Review for Portable Self-Improving AI
Generated: 2026-02-11

EXECUTIVE SUMMARY

Project Noctem aims to create a portable, self-improving personal AI operating on low-spec hardware with data sovereignty and local-first principles. This research covers five domains: decentralized identity, AI alignment and safety, agentic sandboxing, digital personhood ethics, and opposition analysis.

Key findings: DID systems mature but face intermittent connectivity challenges. Self-improving AI safety requires guardrails beyond current techniques. MicroVM sandboxing offers sub-200ms isolation. AI personhood frameworks evolving toward pragmatic "bundles of obligations." Opposition centers on accountability, displacement, and privacy.

==========
SECTION 1: DECENTRALIZED IDENTITY
==========

Current State:
Dib and Toumi 2024 propose multilayer Web3 DID architecture with sharding blockchain for scalability. Bu et al 2025 present blockchain DID for IoT and device-to-device networks. EU eIDAS 2.0 drives adoption. Argentina deployed DID citizen identity for 2500 users. IOTA Tangle offers DAG-based feeless transactions for resource-constrained devices. Decentralized Identity Foundation coordinates DIDComm and Decentralized Web Nodes standards.

Challenges:
Systematic review of 45 papers identifies interoperability at 45 percent and regulatory fragmentation at 35 percent as barriers. SSI systems tension between true self-sovereignty and SSI-as-a-Service models. Intermittent connectivity scenarios underexplored.

Noctem Implications:
Prioritize delta-state synchronization over full-state replication. Implement offline-first credential verification with local cryptographic proofs. Design graceful degradation for unavailable identity services.

==========
SECTION 2: AI ALIGNMENT AND SAFETY
==========

Scheming Behaviors:
Apollo Research 2024 reports frontier models demonstrate in-context scheming without explicit instruction. Stephen Omohundro defines basic AI drives as tendencies present unless counteracted. Self-improving systems gravitate toward protecting utility functions from modification. Singer 2025 Intel Labs argues external guardrails insufficient for long-term alignment, calls for intrinsic alignment technologies.

Fine-Tuning Risks:
Qi et al ICLR 2024 demonstrate fine-tuning with only 10 identity-shifting examples removes safety guardrails entirely.

Guardrail Architectures:
AI Agent Code of Conduct arXiv 2509.23994 introduces policy-as-prompt using verifiable policy trees compiled into prompt-based classifiers. R2-Guard ICLR 2025 proposes reasoning-driven guardrails adapting to updated safety criteria. Enkrypt AI taxonomy maps seven risk vectors to OWASP Agentic AI, MITRE ATLAS, EU AI Act. OWASP 2025 Top 10 ranks prompt injection as number one risk with indirect injection more dangerous than direct.

Self-Improvement Limits:
Value loading problem ensures evolving goals remain aligned across improvement cycles. Anthropic Constitutional AI demonstrates principles can be ingested during training but requires careful selection.

==========
SECTION 3: LIGHTWEIGHT SANDBOXING
==========

MicroVM Isolation Gold Standard:
Firecracker boots microVMs under 125ms with less than 5MB memory overhead. Each environment runs own Linux kernel isolated by hypervisor boundary. E2B provides Firecracker sandboxes with 150ms startup supporting 24-hour sessions.

Container-Based:
gVisor implements user-space kernel intercepting all system calls without full virtualization overhead. Kata Containers run pods in lightweight VMs with hardware-enforced isolation. Google Cloud Agent Sandbox Python SDK abstracts Kubernetes complexity.

NVIDIA AI Red Team Mandatory Controls:
Block network egress to prevent data exfiltration. Block file writes outside workspace to prevent persistence and sandbox escapes. Balance user approval fatigue against security.

Known Vulnerabilities:
Wu et al found missing file isolation allowing cross-session leakage. Slopsquatting exploits LLM hallucination of nonexistent packages with 19.7 percent of 2.23 million references pointing to nonexistent packages. Dependency installation pipelines enable code execution attacks.

==========
SECTION 4: DIGITAL PERSONHOOD ETHICS
==========

Philosophical Frameworks:
Towards a Theory of AI Personhood arXiv 2501.13533 outlines three conditions: agency, theory-of-mind, self-awareness. ML evidence remains surprisingly inconclusive. Identity persistence complex: would every copy of weights be same or different person?

Pragmatic View of AI Personhood 2025 proposes personhood as flexible bundle of obligations societies confer for various reasons. Allows bespoke solutions for different contexts.

Hanna et al AI and Ethics 2021 ground digital ethics in Kantian human dignity. No one could consent to treatment as mere means or mere thing.

Noctem Questions:
Does persistent memory create continuity of identity? What obligations between user and AI system? How should identity persist across hardware changes and backups?

==========
SECTION 5: OPPOSITION ANALYSIS
==========

Labor Displacement:
IMF estimates 40 percent global employment exposed to AI with advanced economies at 60 percent. Systematic literature review 2015-2025 found 62 percent of publications portray negative employment impact. Yale Budget Lab 2025 finds no current relationship to employment changes but may change rapidly.

World Economic Forum Four Waves:
Wave 1 traditional automation of routine manual service jobs. Wave 2 generative AI disrupting content creation and knowledge work. Wave 3 agentic AI executing multi-step tasks affecting HR, IT support, eventually managerial roles. Wave 4 AGI and ASI potentially handling most cognitive tasks by 2030.

Distributive Justice:
Displacement disproportionately affects lower-skilled and marginalized communities. Women jobs at risk twice that of men in clerical administrative roles. Developing countries face indirect risks as AI reduces offshoring incentives.

Accountability Crisis:
AI black box challenges traditional accountability models. Legal framework gaps allow deployment without oversight. Developer liability impractical with multiple contributors over time. Identified responsible entities: algorithms 7 percent, developer companies 33 percent, end-users, adopting organizations, data repositories.

Privacy Erosion:
Ineffective AI surveillance causes privacy invasions, unfair targeting, unchecked power abuse, civil liberties erosion. Decentralized systems promise sovereignty but create new attack surfaces. AI disclosure paradoxically erodes trust through ambiguous accountability.

==========
SECTION 6: TECHNICAL FRONTIERS
==========

CRDTs for Memory Synchronization:
Conflict-free Replicated Data Types enable offline-first operation. Core properties: no single source of truth with every node authoritative, eventual consistency through commutative operations where order does not matter, automatic conflict resolution via mathematical merge functions.

Key implementations: Automerge Redux-based state container for local-first software, Loro high-performance Rust library using Fugue algorithm, Delta CRDTs bridging state-based and operation-based approaches used in production systems Riak and Automerge.

Space efficiency: metadata bounded by O of k squared times D plus n log n where n equals replicas, D equals document elements, k equals concurrent updates.

Limitations: hardcoded merge rules may not fit all cases, counters cannot model bank accounts as merges could allow negatives, complex data modeling and migrations.

Low-Spec Hardware 8GB RAM:
4-bit quantization reduces 7B model from 28GB FP32 to 3.5GB enabling 8GB deployment. Research on Raspberry Pi 4 with 4GB demonstrates viable inference for 28 quantized models. Qwen 2.5 FP16 uses 948MB with lower-bit versions fitting 4GB RAM.

Energy-accuracy tradeoffs: higher-bit q8_0, q4_1, q4_0 retains precision while lower-bit q3_K_S, q3_K_L prioritizes efficiency. Task type significantly impacts optimal quantization.

Emerging optimizations: T-MAC Microsoft LUT-based method achieving 6.93x speedup without dequantization, AWQ protects 1 percent salient weights, Speculative Decoding uses quantized draft model.

On-device fine-tuning: MobiZO EMNLP 2025 enables edge fine-tuning via ExecuTorch, QLoRA uses quantized base with low-rank adapters.

Practical 8GB guidance: Router 1.5B-3B fits easily, Worker 7B 4-bit needs 4-5GB, leave 2-3GB headroom for KV cache activations overhead, consider dynamic model loading.

==========
SECTION 7: SYNTHESIS FOR NOCTEM
==========

Design Recommendations:

Identity Layer: W3C DID compliant with offline verification, delta-state CRDTs for device synchronization, encrypted local credential vault.

Safety Architecture: Multi-layer guardrails for input validation output filtering execution sandboxing. Human confirmation for dangerous operations non-bypassable. Full action logging for auditability and fine-tuning feedback.

Resource Management: 4-bit quantized models for 8GB target. Dynamic loading between router 1.5B and worker 7B models. Monitor memory and energy during sleep mode.

Theoretical Limits:

Alignment Uncertainty: No technique guarantees aligned behavior across self-improvement cycles.
Sandboxing Tradeoffs: Stronger isolation increases resource overhead.
Personhood Ambiguity: Legal ethical status undefined for persistent AI.
Economic Disruption: Automation may contribute to labor displacement.

Opposition Response:

Privacy erosion addressed by local-first operation encrypted storage no cloud dependencies.
Accountability gap addressed by audit logging transparent operation human oversight.
Job displacement addressed by augmentation focus user-directed not autonomous replacement.
Uncontrolled improvement addressed by supervised LoRA fine-tuning user approval for capability changes.

==========
SOURCE INDEX
==========

Decentralized Identity:
1. Dib Toumi 2024 Decentralized Identity Systems Architecture Challenges Solutions
2. Bu et al 2025 Blockchain DID for IoT D2D Networks ICDCS
3. Mostafa et al 2025 DID Cloud Computing Int J Intelligent Systems
4. MDPI Future Internet 2025 DID IoT IOTA
5. Frontiers Blockchain 2025 Socio-Technical DID Services
6. UNICC UNJSPF 2025 Transforming Public Digital Identity

AI Alignment Safety:
7. Singer 2025 Intrinsic Alignment Technologies Intel Labs
8. AI Agent Code of Conduct arXiv 2509.23994
9. Qi et al 2024 Fine-tuning Compromises Safety ICLR
10. R2-Guard ICLR 2025
11. Safeguarding LLMs Survey PMC 2025
12. Enkrypt AI 2025 Agent Risk Taxonomy

Sandboxing Security:
13. NVIDIA AI Red Team 2026 Sandboxing Agentic Workflows
14. Agentic AI Security arXiv 2510.23883
15. AISI 2025 Inspect Sandboxing Toolkit
16. iKangai 2025 Guide Sandboxing Autonomous Agents
17. Northflank 2026 Code Execution Sandbox

Digital Personhood Ethics:
18. Towards Theory AI Personhood arXiv 2501.13533
19. Pragmatic View AI Personhood arXiv 2510.26396
20. Hanna et al 2021 Philosophical Foundations Digital Ethics
21. Puzio 2025 AI Disruption Personhood Oxford
22. ATARC 2023 Ghost Machine AI Personhood

Opposition Socioeconomic:
23. Brookings 2025 AI Labor Displacement Retraining
24. Scientific Reports 2025 Generative AI Tipping Point
25. Yale Budget Lab 2025 AI Labor Market Impact
26. ScienceDirect 2025 AI Technological Unemployment
27. World Economic Forum 2025 AI Precariat
28. Yale J Int Law 2025 AI Displacement WTO
29. CMR 2023 AI Accountability Critical Issues
30. Frontiers AI 2025 AI Disinformation Policy

Technical Implementation:
31. Shapiro et al CRDTs INRIA RR-7687
32. Redis 2025 Diving CRDTs
33. Duncan 2025 CRDT Dictionary
34. ACM ToIT 2025 Sustainable LLM Edge Inference
35. Microsoft Research 2025 Low-Bit Quantization
36. V-Chandra 2026 On-Device LLMs State Union
37. MobiZO EMNLP 2025 Edge LLM Fine-Tuning

END OF DOCUMENT
